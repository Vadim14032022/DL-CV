----------------------------------------------------------------
        Layer (type)               Output Shape         Param #
================================================================
            Conv2d-1         [-1, 64, 100, 100]           1,792
              ReLU-2         [-1, 64, 100, 100]               0
            Conv2d-3         [-1, 64, 100, 100]          36,928
              ReLU-4         [-1, 64, 100, 100]               0
         MaxPool2d-5           [-1, 64, 50, 50]               0
            Conv2d-6          [-1, 128, 50, 50]          73,856
              ReLU-7          [-1, 128, 50, 50]               0
            Conv2d-8          [-1, 128, 50, 50]         147,584
              ReLU-9          [-1, 128, 50, 50]               0
        MaxPool2d-10          [-1, 128, 25, 25]               0
           Conv2d-11          [-1, 256, 25, 25]         295,168
             ReLU-12          [-1, 256, 25, 25]               0
           Conv2d-13          [-1, 256, 25, 25]         590,080
             ReLU-14          [-1, 256, 25, 25]               0
           Conv2d-15          [-1, 256, 25, 25]         590,080
             ReLU-16          [-1, 256, 25, 25]               0
        MaxPool2d-17          [-1, 256, 12, 12]               0
           Conv2d-18          [-1, 512, 12, 12]       1,180,160
             ReLU-19          [-1, 512, 12, 12]               0
           Conv2d-20          [-1, 512, 12, 12]       2,359,808
             ReLU-21          [-1, 512, 12, 12]               0
           Conv2d-22          [-1, 512, 12, 12]       2,359,808
             ReLU-23          [-1, 512, 12, 12]               0
        MaxPool2d-24            [-1, 512, 6, 6]               0
           Conv2d-25            [-1, 512, 6, 6]       2,359,808
             ReLU-26            [-1, 512, 6, 6]               0
           Conv2d-27            [-1, 512, 6, 6]       2,359,808
             ReLU-28            [-1, 512, 6, 6]               0
           Conv2d-29            [-1, 512, 6, 6]       2,359,808
             ReLU-30            [-1, 512, 6, 6]               0
        MaxPool2d-31            [-1, 512, 3, 3]               0
AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0
      BatchNorm1d-33                [-1, 25088]          50,176
           Linear-34                   [-1, 42]       1,053,738
              VGG-35                   [-1, 42]               0
================================================================
Total params: 15,818,602
Trainable params: 10,543,146
Non-trainable params: 5,275,456
----------------------------------------------------------------
Input size (MB): 0.11
Forward/backward pass size (MB): 43.51
Params size (MB): 60.34
Estimated Total Size (MB): 103.97
----------------------------------------------------------------
VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): ReLU(inplace=True)
    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (6): ReLU(inplace=True)
    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (8): ReLU(inplace=True)
    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (11): ReLU(inplace=True)
    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (13): ReLU(inplace=True)
    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (15): ReLU(inplace=True)
    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (18): ReLU(inplace=True)
    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (20): ReLU(inplace=True)
    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (22): ReLU(inplace=True)
    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (25): ReLU(inplace=True)
    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (27): ReLU(inplace=True)
    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (29): ReLU(inplace=True)
    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): BatchNorm1d(25088, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (1): Linear(in_features=25088, out_features=42, bias=True)
  )
)
Epoch  train_loss  train_acc  val_loss  val_acc
    1    0.526097   0.874799  1.836123 0.784795
    2    0.353419   0.911090  1.283546 0.908484
    3    0.246327   0.933381  1.127119 0.906794
    4    0.194291   0.948814  1.364618 0.929678
    5    0.169164   0.954892  1.559287 0.926341
    6    0.235403   0.942673  1.863406 0.900858
    7    0.160758   0.956200  1.231593 0.948761
    8    0.106469   0.970445  0.514504 0.949940
    9    0.057377   0.982839  0.763286 0.971395
   10    0.051966   0.984567  1.146481 0.977831
   11    0.089073   0.975746  4.017681 0.922545
   12    0.176805   0.957750  1.265989 0.903480
   13    0.117532   0.970623  1.201136 0.955185
   14    0.050044   0.985639  1.516287 0.947795
   15    0.066584   0.983315  0.747363 0.982122
   16    0.025972   0.993624  1.903046 0.980696
   17    0.008475   0.996842  1.579375 0.980696
   18    0.008146   0.997497  0.446054 0.988081
   19    0.006490   0.998272  0.992633 0.986889
   20    0.003761   0.998927  1.443795 0.984744
   21    0.003608   0.999225  1.226755 0.987131
   22    0.003204   0.999106  2.225104 0.984747
   23    0.003448   0.999166  1.017321 0.986412
   24    0.002531   0.999285  0.502144 0.989273
   25    0.003514   0.999345  0.563915 0.987843
   26    0.001891   0.999642  0.919956 0.988799
   27    0.002845   0.999344  0.875667 0.987846
   28    0.001763   0.999583  1.611889 0.981168
   29    0.002507   0.999404  0.754146 0.986889
   30    0.002818   0.999404  1.109737 0.981883
   31    0.001736   0.999404  1.410264 0.984986
   32    0.000972   0.999404  1.448187 0.986892
   33    0.002104   0.999345  1.266654 0.986651
   34    0.001243   0.999523  0.979188 0.982598
   35    0.000972   0.999762  1.119776 0.985936
   36    0.001776   0.999583  0.617487 0.988799
   37    0.001034   0.999642  1.579412 0.982602
   38    0.000889   0.999583  1.487075 0.989273
   39    0.000682   0.999762  1.229382 0.986889
   40    0.001232   0.999583  0.932362 0.983790
   41    0.001344   0.999464  0.844912 0.987369
   42    0.000933   0.999762  0.779622 0.988084
   43    0.000948   0.999762  2.265545 0.978546